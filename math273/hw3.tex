\documentclass{article}
\usepackage{geometry}
\usepackage[namelimits,sumlimits]{amsmath}
\usepackage{amssymb,amsfonts}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage[cm]{fullpage}
\usepackage{subfigure}
\usepackage{float}
\newcommand{\nc}{\newcommand}
\newcommand{\tab}{\hspace*{5em}}
\newcommand{\conj}{\overline}
\newcommand{\dd}{\partial}
\nc{\cn}{\mathbb{C}}
\nc{\rn}{\mathbb{R}}
\nc{\vphi}{\varphi}
\nc{\openm}{\begin{pmatrix}}
\nc{\closem}{\end{pmatrix}}
\nc{\pd}[2]{\frac{\partial {#1}}{\partial {#2}}}
\nc{\ep}{\epsilon}
\setlength{\parindent}{0mm}
\DeclareMathOperator{\tr}{tr}
\begin{document}
Name: Hall Liu

Date: \today 
\vspace{1.5cm}

\subsection*{2.7.2}
First, consider the fundamental matrix $Y$obtained by calculating $e^{\lambda_it}e^{A-\lambda_iI}v_j$ and using them as columns, where $v_j$ is a generalized eigenvector corresponding to the eigenvalue $\lambda_i$. If $\lambda_i$ is simple, then the series expansion for $e^{A-\lambda_iI}$ terminates after the identity, so any entry in $Y$ containing a $e^{\lambda_it}$ has at most a constant term in front of it.

Going back to the argument in the proof of theorem 2.10, we obtain any solution by multiplying $Y$ by some matrix constant in $t$. Thus, the resulting solution vector will have in each entry some expression of the form $\sum_{j=1}^kp_j(t)e^{\lambda_jt}$. Now, if we examine the behavior of this as $t\to\infty$, we have that for all $\Re(\lambda_j)<0$, the exponential term dominates the polynomial term and goes to $0$. For $\Re(\lambda_j)=0$, the exponential part is bounded and oscillating, but its associated polynomial part is constant, so the term remains bounded also. Add up a finite number of these and it's still bounded. 
\subsection*{2.7.3}
Let $Y$ be the fundamental matrix referenced in the previous problem. For any solution of the inhomogenous equation with initial conditions $\eta$, we have $\phi(t)=Y(t)Y^{-1}(t_0)\eta+\int_{t_0}^tY(t)Y^{-1}(s)g(s)ds$. Assuming that the equation satisfies the hypotheses, the first term is automatically bounded because it's a solution of the homogenous equation. Now examine the integral, ignoring the $Y(t)$ term for now. We have that the entries of $Y^{-1}(s)$ are linear combinations of the elements of $Y(s)$ (its cofactors) divided by the determinant, which in turn evolves according to $\exp\left(\int_{t_0}^t\tr(A) ds\right)$. The trace is simply the sum of the eigenvalues of $A$, which we know to be negative, so the determinant goes to zero faster than any of the entries of the cofactor matrix. 

The discussion of the determinant of $Y$ implies then that the entries of $Y^{-1}(s)$ are monotonically increasing for large enough $s$. Thus, $\int_{t_0}^tY^{-1}(s)g(s)ds$ is bounded above by $\int_{t_0}^tY^{-1}(t)g(s)ds$. Pulling out the $Y^{-1}(t)$ lets it cancel out with the $Y(t)$ that was there out front, so the entire second term is bounded above by the integral of $g(s)$. Assuming then that this is bounded, we have that $\phi(t)$ is bounded.
\subsection*{2.8.2,3,4}
\begin{figure}[H]
\mbox{\subfigure[2.8.2]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_2.pdf}}
      \subfigure[2.8.3]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_3.pdf}}
      \subfigure[2.8.4]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_4.pdf}}}
\end{figure}
\subsection*{2.8.5}
See Figure \ref{578}
Note: Mathematica wouldn't let me plot anything that had a variable like $g/L$ in it, so I'm going to assume that $L=1m$.

\subsection*{2.8.6}
Any solution with eigenvalues as described will have exponentially increasing terms in $t$ in both components, causing the overall vector to evolve away from $0$ as $t$ increases.
\subsection*{2.8.7}
See Figure \ref{578}. Numbers mean nothing. I just did something to get the overall shape.
\subsection*{2.8.8}
See Figure \ref{578}
\begin{figure}[H]
\mbox{\subfigure[2.8.5]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_5.pdf}}
     \subfigure[2.8.7]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_7.pdf}}
     \subfigure[2.8.8]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_8.png}}}
\caption{5,7,8}
\label{578}
\end{figure}
\subsection*{2.8.9}
See Figure \ref{91011}
\subsection*{2.8.10}
See Figure \ref{91011}
\begin{figure}[H]
\mbox{\subfigure[2.8.9]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_9.png}}
     \subfigure[2.8.10]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_10.png}}
     \subfigure[2.8.11]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_11.png}}}
\caption{9,10,11}
\label{91011}
\end{figure}

\subsection*{2.8.11}
For 11-19, if we write the scalar equation as $x''+px'+qx=0$, the matrices are all going to be in the form $\openm0&1\\-q&-p\closem$. The characteristic polynomial is simply $\lambda^2+p\lambda+q$. If $p^2>4q$, then we end up in case i or iii. If $p^2<4q$, then we end up in case v or vi. The only one for which $p^2=4q$ is 17, but it's kinda annoying to do it in symbols so we'll take care of it when we get there.

Now, for 11. Here $p=0,q=1$, so this is case vi with eigenvalues $\pm i$. See Figure \ref{91011}. Origin is not an attractor.

\subsection*{2.8.12}
$p^2>4q$ here, and the eigenvalues turn out to be both positive, so this is a case i. Origin is not an attractor. See Figure \ref{121314}
\subsection*{2.8.13}
Same thing as above, though now the eigenvalues are both negative. Origin is an attractor. See Figure \ref{121314}
\subsection*{2.8.14}
$p^2>4q$ still, but now the eigenvalues are one above and one below zero. Origin is not an attractor. See Figure \ref{121314}

\begin{figure}[H]
\mbox{\subfigure[2.8.12]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_12.png}}
     \subfigure[2.8.13]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_13.png}}
     \subfigure[2.8.14]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_14.png}}}
\caption{12,13,14}
\label{121314}
\end{figure}

\subsection*{2.8.15}
Eigenvalues are $1$ and $2$. Case i. Origin not an attractor. See Figure \ref{151617}
\subsection*{2.8.16}
Eigenvalues are $-1$ and $-2$. Case i. Origin is an attractor. See Figure \ref{151617} 
\subsection*{2.8.17}
There is only one eigenvalue, $1$. It's case iv, and the origin is not an attractor. See Figure \ref{151617}

\begin{figure}[H]
\mbox{\subfigure[2.8.15]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_15.png}}
     \subfigure[2.8.16]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_16.png}}
     \subfigure[2.8.17]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_17.png}}}
\caption{15,16,17}
\label{151617}
\end{figure}

\subsection*{2.8.18}
Eigenvalues are crossed positive-negative, so it's case iii. Origin is not an attractor. See Figure \ref{1819}
\subsection*{2.8.19}
a. Consider all points $y_1=y_2$. Applying the matrix $\openm1&-1\\2&-2\closem$ to this, we see that all such points are in the kernel, so all such points are critical points of the system. 

b. See Figure \ref{1819}
\begin{figure}[H]
\mbox{\subfigure[2.8.18]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_18.png}}
     \subfigure[2.8.19]{\includegraphics[width=0.33\textwidth]{scripts_3/2_8_19.png}}}
\caption{18,19}
\label{1819}
\end{figure}

\end{document}
